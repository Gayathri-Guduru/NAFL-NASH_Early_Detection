```{r}
# Install required packages if not already installed
if (!requireNamespace("BiocManager", quietly = TRUE)) {
    install.packages("BiocManager")
}
# Uncomment to install the necessary packages if not already installed
 #BiocManager::install(c("GEOquery", "limma", "clusterProfiler", "org.Hs.eg.db", "KEGGREST", "msigdbr"))

# Load necessary libraries
library(GEOquery)
library(limma)
library(clusterProfiler)
library(org.Hs.eg.db)
library(KEGGREST)
library(msigdbr)
library(ggplot2)
library(pheatmap)
library(randomForest)
library(caret)
library(xgboost)
library(e1071)
library(smotefamily)
#install.packages("DMwR2")
#library(DMwR2)

### Step 1: Download and Preprocess GEO Dataset (GSE182060)
# Download GSE182060 dataset from GEO
# Check if the file is already downloaded and available locally
local_file <- "C:/Users/gguduru/OneDrive - Zymo Research/Local/Metagenomic_mock/amr_data/subset_15/NAFL/GSE182060_series_matrix.txt.gz"

if (file.exists(local_file)) {
  gse182060 <- getGEO(filename = local_file)
} else {
  gse182060 <- getGEO("GSE182060", GSEMatrix = TRUE)[[1]]
}


# Function to preprocess data (log2 transformation and normalization)
preprocess_data <- function(gse) {
  exprs_data <- exprs(gse)
  
  # Log2 transformation if necessary
  if (max(exprs_data) > 100) {
    exprs_data <- log2(exprs_data + 1)
  }
  
  # Normalize between arrays using limma
  exprs_data <- normalizeBetweenArrays(exprs_data)
  return(exprs_data)
}

# Preprocess the expression data
exprs_182060 <- preprocess_data(gse182060)
```

### Explanation:
# Log2 transformation is applied to normalize the dataset, making the values comparable and reducing large variations in gene expression. 
# Normalization is performed to ensure that comparisons across different samples (Baseline vs Follow-up) are accurate.

```{r}
### Step 2: Differential Expression Analysis (Baseline vs. Follow-up)
# Extract phenotype data
pheno_182060 <- pData(gse182060)

# Subset data to include only Baseline and Follow-up samples
valid_samples <- pheno_182060$`time_point:ch1` %in% c("Baseline", "Follow-up")
exprs_subset <- exprs_182060[, valid_samples]
pheno_subset <- pheno_182060[valid_samples, ]

# Create design matrix (pairing by patient)
design <- model.matrix(~ pheno_subset$`time_point:ch1` + pheno_subset$`patient:ch1`)
colnames(design)[2] <- "Follow_up"

# Perform linear modeling and empirical Bayes statistics using limma
fit <- lmFit(exprs_subset, design)
fit <- eBayes(fit)

# Extract top differentially expressed genes (adjusted p-value and logFC thresholds)
results_182060 <- topTable(fit, coef = "Follow_up", adjust.method = "fdr", number = Inf)
head(results_182060)
significant_genes <- results_182060[results_182060$adj.P.Val < 0.1 & abs(results_182060$logFC) > 0.05, ]
nrow(significant_genes)  # Number of significant genes
```


### Explanation:
# Differential Expression Analysis is performed to identify genes that show significant expression changes between Baseline and Follow-up samples. 
# The "logFC" tells how much a gene's expression changes between conditions, and "adj.P.Val" indicates the statistical significance of these changes (after adjusting for multiple tests).
# Genes with large logFC values and low adjusted p-values are considered biologically significant.



```{r}
### Step 3: KEGG Pathway Enrichment Analysis
# Convert gene symbols to Entrez IDs for KEGG enrichment
symbol_to_entrez <- bitr(rownames(significant_genes), fromType = "SYMBOL", toType = "ENTREZID", OrgDb = org.Hs.eg.db)
entrez_ids <- symbol_to_entrez$ENTREZID

# Perform KEGG pathway enrichment using Entrez IDs
kegg_results_local <- enrichKEGG(gene = entrez_ids, organism = "hsa", keyType = "ncbi-geneid")
head(kegg_results_local)  # View top KEGG results

# Save KEGG pathway enrichment results to a CSV file
write.csv(as.data.frame(kegg_results_local), file = "GSE182060_KEGG_Pathway_Results.csv")
```

### Explanation:
# Pathway enrichment analysis helps to identify biological pathways (e.g., metabolic, immune signaling) that are overrepresented among the differentially expressed genes.
# KEGG pathways represent specific biochemical and signal transduction pathways, providing insights into the underlying biological mechanisms impacted by the changes in gene expression.



```{r}
### Step 4: Gene Set Enrichment Analysis (GSEA) for GO Biological Processes
gsea_significant_genes <- rownames(significant_genes)

# Perform GSEA using GO Biological Processes (BP)
gsea_results <- enrichGO(gene = gsea_significant_genes, OrgDb = org.Hs.eg.db, keyType = "SYMBOL", ont = "BP")
head(gsea_results)  # View top GSEA results

# Save GSEA results for GO Biological Processes
write.csv(as.data.frame(gsea_results), file = "GSE182060_GSEA_GO_BP.csv")
```

### Explanation:
# Gene Ontology (GO) enrichment analysis focuses on biological processes that are significantly associated with the set of differentially expressed genes.
# This can reveal insights into biological functions such as cell cycle, immune response, or metabolic processes affected by the changes in gene expression.


```{r}
### Step 5: GSEA for Predefined KEGG Gene Sets (using msigdbr)
# Load KEGG gene sets using msigdbr
kegg_gene_sets <- msigdbr(species = "Homo sapiens", category = "C2", subcategory = "CP:KEGG")

# Perform GSEA using KEGG gene sets from msigdbr
kegg_enrichment_msigdbr <- enricher(gene = gsea_significant_genes, TERM2GENE = kegg_gene_sets[, c("gs_name", "gene_symbol")])
head(kegg_enrichment_msigdbr)  # View KEGG GSEA results

# Save KEGG GSEA results
write.csv(as.data.frame(kegg_enrichment_msigdbr), file = "GSE182060_KEGG_GSEA_msigdbr.csv")
```

### Explanation:
# KEGG gene sets from msigdbr provide an alternative way of exploring KEGG pathways, specifically using predefined gene sets associated with these pathways.
# Performing GSEA on these predefined sets helps identify whether specific pathways are enriched among your significant genes.

```{r}
### Step 6: Visualization
# Create a volcano plot for the differentially expressed genes
volcano_data <- data.frame(logFC = results_182060$logFC, adj.P.Val = results_182060$adj.P.Val)
volcano_plot <- ggplot(volcano_data, aes(x = logFC, y = -log10(adj.P.Val))) +
  geom_point(alpha = 0.4) +
  theme_minimal() +
  xlab("Log Fold Change") +
  ylab("-log10 Adjusted P-value") +
  ggtitle("Volcano Plot - GSE182060 (Baseline vs. Follow-up)")

# Save the volcano plot as a JPEG
ggsave(volcano_plot, filename = "volcano_plot_GSE182060.jpeg", width = 8, height = 6)

# Create a heatmap for the top 20 differentially expressed genes
top_genes <- rownames(head(results_182060, 20))
exprs_top_genes <- exprs_182060[top_genes, ]
heatmap_plot <- pheatmap(exprs_top_genes, scale = "row", show_rownames = TRUE, cluster_cols = TRUE)

# Save the heatmap as a JPEG
ggsave(heatmap_plot, filename = "heatmap_GSE182060.jpeg", device = "jpeg", height = 6, width = 22, units = "in")
```

### Explanation:
- **Volcano Plot**: This plot provides an overview of which genes are most significantly differentially expressed (y-axis shows significance, x-axis shows magnitude of change). Genes with high logFC and low p-values are of particular interest.
- **Heatmap**: The heatmap visualizes the expression patterns of the top 20 differentially expressed genes across samples. This can reveal clustering patterns, indicating gene expression trends between Baseline and Follow-up samples.

### Final Interpretation:
- **Upregulated Genes (Positive logFC)**: These genes are more highly expressed in Follow-up, potentially pointing to pathways or biological processes that are activated over time or with treatment.
- **Downregulated Genes (Negative logFC)**: These genes are less expressed in Follow-up, suggesting they may be involved in processes that are suppressed during disease progression or treatment.
- **GSEA/KEGG Pathways**: The enriched pathways provide insights into how the changes in gene expression affect biological functions, potentially identifying key mechanisms related to liver disease, recovery, or treatment response.

## By choosing Random Forest and XGBoost, you benefit from robustness, feature selection, and scalability, making these models particularly well-suited for your dataset.

## script for Random forest:
Random Forest is used for its ability to handle high-dimensional data (many genes) and for its feature importance ranking.
```{r}
# Ensure the necessary libraries are loaded
library(randomForest)
library(caret)

### Step 7: Prepare Data for Machine Learning
sig_genes_gse182060 <- rownames(significant_genes)

# Transpose the expression data for machine learning (rows as samples, columns as genes)
expr_data <- t(exprs_182060[sig_genes_gse182060, ])

# Create a data frame with expression data and the condition (Baseline vs Follow-up)
labels <- pheno_subset$`time_point:ch1`
df <- as.data.frame(expr_data)
df$labels <- as.factor(labels)

# Step 8: Split Data into Training and Testing Sets
# If there is a class imbalance between Baseline and Follow-up samples, SMOTE can be applied here.
# df_balanced <- SMOTE(labels ~ ., data = train_data, perc.over = 200, perc.under = 100)

set.seed(123)
trainIndex <- createDataPartition(df$labels, p = 0.7, list = FALSE)
train_data <- df[trainIndex, ]
test_data <- df[-trainIndex, ]

# Step 9: Train Random Forest Model
# Train the Random Forest model on the training data and evaluate it on the test data.
rf_model <- randomForest(labels ~ ., data = train_data, ntree = 500, importance = TRUE)

# Evaluate the model on the test data
rf_predictions <- predict(rf_model, newdata = test_data)
conf_matrix <- confusionMatrix(rf_predictions, test_data$labels)
print(conf_matrix)

# View feature importance
importance(rf_model)
varImpPlot(rf_model)

# Save the model and important features
save(rf_model, file = "random_forest_model.RData")
write.csv(importance(rf_model), file = "random_forest_feature_importance.csv")
```
### Interpretation:
# Random Forest model is used due to its robustness in handling high-dimensional data and its ability to rank features by importance.
# The model accuracy and confusion matrix provide insights into its classification performance. The importance of specific genes in the model can help identify potential biomarkers.


## script for XGBoost
XGBoost is chosen for its gradient boosting framework, which improves accuracy by sequentially building trees and is more robust to overfitting.

```{r}
# Step 10: Prepare Data for Machine Learning
# Use the significant genes from the differential expression analysis
sig_genes_gse182060 <- rownames(significant_genes)

# Transpose the expression data for machine learning (rows as samples, columns as genes)
expr_data <- t(exprs_182060[sig_genes_gse182060, ])

# Create a data frame with expression data and the condition (Baseline vs Follow-up)
labels <- pheno_subset$`time_point:ch1`
df <- as.data.frame(expr_data)
df$labels <- as.factor(labels)

# Ensure all columns are numeric (XGBoost requires numeric input)
df_numeric <- df
df_numeric$labels_numeric <- as.numeric(df_numeric$labels) - 1  # Convert labels to 0 and 1

# Remove non-numeric columns (if any exist)
df_numeric <- df_numeric[, sapply(df_numeric, is.numeric)]

# Step 11: Split Data into Training and Testing Sets
set.seed(123)
trainIndex <- createDataPartition(df_numeric$labels_numeric, p = 0.7, list = FALSE)
train_data <- df_numeric[trainIndex, ]
test_data <- df_numeric[-trainIndex, ]

# Step 12: Prepare Data for XGBoost
# Create matrices for XGBoost
train_matrix <- xgb.DMatrix(data = as.matrix(train_data[, -ncol(train_data)]), label = train_data$labels_numeric)
test_matrix <- xgb.DMatrix(data = as.matrix(test_data[, -ncol(test_data)]), label = test_data$labels_numeric)

# Step 13: Train XGBoost Model
params <- list(
  objective = "binary:logistic",  # For binary classification
  eval_metric = "logloss",        # Logarithmic loss metric
  booster = "gbtree",             # Use tree-based models
  max_depth = 6,                  # Depth of the trees
  eta = 0.1,                      # Learning rate
  gamma = 0,                      # Minimum loss reduction
  subsample = 0.8,                # Subsample ratio of the training instance
  colsample_bytree = 0.8          # Subsample ratio of columns when constructing each tree
)

# Train the model using cross-validation to avoid overfitting
xgb_model <- xgb.train(params = params, data = train_matrix, nrounds = 100, 
                       watchlist = list(train = train_matrix, test = test_matrix),
                       early_stopping_rounds = 10, verbose = 0)

# Step 14: Evaluate XGBoost Model
# Make predictions on the test data
xgb_predictions_prob <- predict(xgb_model, test_matrix)
xgb_predictions <- ifelse(xgb_predictions_prob > 0.5, 1, 0)

# Convert numerical predictions and true labels to factors with matching levels
xgb_predictions <- factor(xgb_predictions, levels = c(0, 1))
test_labels_factor <- factor(test_data$labels_numeric, levels = c(0, 1))

# Confusion Matrix and Performance Metrics
conf_matrix_xgb <- confusionMatrix(xgb_predictions, test_labels_factor)
print(conf_matrix_xgb)

# Save the model
xgb.save(xgb_model, "xgboost_model.model")
# Dump the model into text format
model_dump <- xgb.dump(xgb_model, with_stats = TRUE)
cat(model_dump[1:10])  # Print first 10 lines of the model

# Step 15: Feature Importance
# Get the feature importance
importance_matrix <- xgb.importance(feature_names = colnames(train_data)[-ncol(train_data)], model = xgb_model)
print(importance_matrix)

# Plot the feature importance
xgb.plot.importance(importance_matrix, top_n = 20)
```
### Interpretation:
# XGBoost is more effective at handling complex data with its gradient boosting algorithm, which builds trees sequentially to improve accuracy.
# The confusion matrix shows the classification accuracy, and the model's ability to avoid overfitting is an advantage in biological datasets with many features.

## AUC-ROC Comparison with Cross-Validation:
```{r}
# Assuming you already have trained randomForest and xgboost models

# Install required package if not installed
if (!require(pROC)) install.packages("pROC")
library(pROC)
library(caret)

# Perform 5-fold cross-validation for Random Forest
set.seed(123)

# Check for missing values in the dataset
summary(train_data)

# Rename the factor levels of labels_numeric to valid names
levels(train_data$labels_numeric) <- c("Class0", "Class1")

# Perform 5-fold cross-validation for Random Forest using the corrected labels
set.seed(123)
cv_rf <- train(
  labels_numeric ~ ., data = train_data, method = "rf", 
  trControl = trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary), 
  metric = "ROC"
)

# Perform 5-fold cross-validation for XGBoost
cv_xgb <- train(
  labels_numeric ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary), metric = "ROC"
)

# Compare the average AUC from cross-validation
cat("Random Forest AUC:", max(cv_rf$results$ROC), "\n")
cat("XGBoost AUC:", max(cv_xgb$results$ROC), "\n")
```
### Results:
# Random Forest AUC: 0.8760
# XGBoost AUC: 0.8892

### Conclusion:
# XGBoost slightly outperforms Random Forest in terms of AUC score (0.8892 vs. 0.8760), indicating better classification performance in this dataset.
# Both models show strong performance, but XGBoost’s ability to avoid overfitting and handle complex data with high-dimensional features makes it more suitable for this type of analysis.
